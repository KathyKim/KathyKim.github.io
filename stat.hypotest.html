<!DOCTYPE HTML>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <meta name="Keywords" content="blog"/>
    <meta name="Description" content="blog"/>
    <title>Simple</title>
    <link rel="shortcut icon" href="/static/favicon.png"/>
    <link rel="stylesheet" type="text/css" href="/main.css" />
</head>
<body>
<div class="main">
    <div class="header">
    	<ul id="pages">
            <li><a href="/">home</a></li>
            <li><a href="/#/tags">tags</a></li>
            <li><a href="/#/archive">archive</a></li>
    	</ul>
    </div>
	<div class="wrap-header">
	<h1>
    <a href="/" id="title"></a>
	</h1>
	</div>
<div id="md" style="display: none;">
<!-- markdown -->
#Mathematical Statistical Review Notes

<center>目录</center>

**Mathematical Statistical**

- 假设检验
    - 从几个问题入手
   - 假设检验问题的基本概念
   - 漂亮的定理证明

        - 随机化检验的优良性「充分性原则」
        - Neyman-Pearson 基本引理
        - MPT的一个性质
        - 单调性的力量——单调似然比-统计量-势函数
        - 单边假设检验问题的UMPT
        - N-P基本引理的推广（一）
        - 单参数指数型分布族的双边假设检验问题（一）
        - 单参数指数型分布族的双边假设检验问题（二）

Statistics很火没有错，但是Mathematical Statistical一直一来都不温不火，太优雅门槛高变现不容易。若心浮浮躁躁，想来也是学不下去的。

突然想到自己大三的时候，那时还住在本科院校一个四面环山的校区，突然想到一个事「我们单身的时候都会非常羡慕他人有陪伴，但是单身这种状态本身也是值得享受的呢，而且它持续的时间也不会很长，假设30岁结婚，最多也只有10年。」

比较幸运的是，我在自己单身的时候就明白了这一点，而且充分享受了一个人&无牵绊&宅宅的&简单纯粹&看似孤独实则轻松得想要偷笑的生活。

面对考试前的二十天，虽然不可免俗地要和身边的人共同「抱怨期末考」，但是，如同我对待「一个人的日子」那般，我也会好好享受这段「一支笔&一张纸」就是全部生产力的日子。

那么以下就是我的复习笔记了，也想留下点什么纪念下：）

ps：以下内容并非原创哦！整理自三本参考书：
- [《高等数理统计学》](https://book.douban.com/subject/4102672/)
- [《高等数理统计(第二版)》 ](https://book.douban.com/subject/1832818/)
- [《数理统计学简史》](https://book.douban.com/subject/1522839/)
- [《统计学：从数据到结论》](https://book.douban.com/subject/24316364/)

关于这三本参考书，难度或者说抽象程度，由高到低。
- [《高等数理统计学》》](https://book.douban.com/subject/4102672/)是陈希孺前辈的著作，定位是「基于测度论的数理统计学基础教科书，主体是几种基本统计推断形式：点估计、区间估计、假设检验的理论与方法。」这本书中习题以及提示占了50%的篇幅，的确，基础学科若不以做题加深功底，就如同「入宝山而空返」。
- [《高等数理统计(第二版)》 ](https://book.douban.com/subject/1832818/)是陈希孺的学生们基于教学工作写就的，理论讲解和习题举例结合得比较好，通俗地讲就是比较简单，但是这个简单是相对于《高等数理统计学》而言的哦！
- [《数理统计学简史》](https://book.douban.com/subject/1522839/)也是陈希孺为大众写的一本书，侧重的是统计学的艺术性，其强调人的见解和灵感的部分，这四本书中，唯有这一本阅读人数>100，评分高于9.0, 看来广大豆友们还是偏爱自己能看懂的书（眨眼&不置可否）
- [《统计学：从数据到结论》](https://book.douban.com/subject/24316364/)是吴喜之老先生的著作，比较难能可贵的一点是这本书兼顾统计见解&实用性——书中附有R的代码。看上去非常舒服：）


<center> **那就开始吧** </center>

##1. 假设检验


###1.1 从几个问题入手
常用的U检验、t检验、F检验都有足够的直观性和可信感。再往深处想：


- 一个好的检验究竟「好」在哪里？
- 对于给定的「好坏」标准，是否存在最优的检验方法？
- 如果有，如何找到？




###1.2 假设检验问题的基本概念  
统计结构 $(X, B, P)$中：

1. **假设**：原假设为 $H\_{0}$, 备择假设为$H\_{1}$ ，都是 P 的非空子集，且不相交或者更广义地说，是可以用样本点——「我们的观测值」，来进行检验的「任何说法」。所以啊，样本点身兼两大重任——「参数估计」&「假设检验」。
2. **检验法则** $\leftrightarrow$ 拒绝域 $\rightarrow$ 统计量：检验法则将样本空间划分为互不相交的两个可测集 $X=W \oplus \overline W$ ，当样本点 $x \in W$  时就拒绝原假设 $H_0$ 。
3. **检验统计量**：从另一个角度来看，确定拒绝域也就确定了检验法则，进一步，通常利用一个在$W$和 $\overline W$上表现得非常不一致的统计量来确定拒绝域。
4. **势函数**：样本观察值X落在拒绝域W中的概率，即：

    $g(\theta) = P_{\theta}(X \in W), \theta \in \Theta$ 

    其中:

    第一类错误 $\alpha(\theta) = g(\theta), \theta \in \Theta_{0}$ 

    第二类错误 $\beta(\theta) = 1 - g(\theta), \theta \in \Theta_{1}$  

    唉，忘了怎么写不属于的符号，就只能连式子都改一下了。所以，不同的检验法则会有不同的拒绝域，也就有不同的势函数，不同的犯第一类错误以及第二类错误的可能性
5. **检验的水平**$\alpha$：犯第一类错误概率小于$\alpha$
6. **随机化检验**：为了充分利用检验水平，引入随机化检验作为检验函数$\phi(x)$，此时势函数 $g(\theta) = P_{\theta}(X \in W) = E_{\theta}(\phi(x))$

7. **最优势检验（Most Powerful Test，MPT）**：在大家犯第一类错误的概率都小于$\alpha$的基础上，犯第二类错误最小的检验函数$\phi(x)$即为最优势检验

8. 从MPT到 **Uniformly Most Powerful Test——UMPT**，MPT是在简单原假设Vs简单备择假设的情况下得出的，但是面对复合假设时，如何定义最优？能否找到最优呢？这个问题一下子变得有些复杂。且看之~
**定义UMPT**
$\phi(x)$是水平为$\alpha$的检验，如果对于任意一个水平为$\alpha$的检验$\phi_{1}(x)$，都有$E_{\theta_1}[\phi(X)] > E_{\theta_1}(\phi_{1}(X)),  \forall \theta_1 \in \Theta_1$，则$\phi(X)$就是水平为$\alpha$的UMPT.  (「一致性」表现在随着$ \theta_1 \in \Theta_1$不停地变换，「我」都是最好的哦！)
**借由MPT得到UMPT**
在一些特殊的情况下，可以通过MPT推导出UMPT。例如：当简单原假设对简单备择假设的检验问题的MPT不依赖于备择假设的具体数值，则可以适当扩大备择假设；当势函数是单调函数时，可以扩大**原假设**。BUT，但是在大部分情况下都无法将复杂假设还原到简单原假设，
9. **单调似然比**，概率密度族$\{p(x; \theta): \theta \in \Theta\}$关于统计量$T(X)$有单调似然比$\lambda(x) = \frac{p(x;\theta_2)}{p(x;\theta_1)}, \theta_{2} > \theta_1$
10. **单参数指数族**，$p(x;\theta) = c(\theta)*exp\{Q(\theta)T(x)\}*h(x)$，常见的有二项分布族、Poisson分布族、有1参数已知的正态分布族
11. 从一致最优检验到**一致最优势无偏检验 Uniformly Most Powerful Unbiased Test UMPUT**，无偏检验满足：
$E_{\theta}[\phi(X)] \leqslant \alpha, \forall \theta \in \Theta_{0}$
$E_{\theta}[\phi(X)] \geqslant \alpha, \forall \theta \in \Theta_{1}$
一致最优说的就是:
$E_{\theta}[\phi(X)] \geqslant E_{\theta}[\phi'(X)] , \forall \theta \in \Theta_{1}$
12.从UMPUT到**相似检验**，在$\Theta_{0}$和$\Theta_{1}$的公共边界上势函数相等的检验函数是边界相似检验。构造边界相似检验比构造无偏检验更方便（前者束缚更小），如果$\phi(x)$是边界相似检验中的UMPT，则$\phi(x)$是水平为$\alpha$的UMPUT

###1.3 漂亮的定理证明

####随机化检验的优良性「充分性原则」

检验函数$\Leftrightarrow$势函数。对于任何一个检验函数，存在一个只依赖于$\theta$的充分统计量$T(x)$的另一个检验函数$\varphi(t) = E[\phi(X)| T=t]$，与之等价。
 `证明非常漂亮:` $E_{\theta}[\phi(T(X))] = E_{\theta}\{E[\phi(X)| T]\} = E_{\theta}[\varphi(T)]$
 
#### Neyman-Pearson 基本引理
ok，首先考虑简单原假设对简单备择假设，简而言之就是参数$\theta$到底是$\theta_0$呢？还是$\theta_1$？

在这种最简单的情形下，N-P引理给出了非常漂亮的结果。

> MPT一定存在，且可以具体地构造出MPT的检验函数。

原假设$\theta = \theta_0$
备择假设$\theta = \theta_1$
分别对应两个不同的概率测度$P_{\theta_0}$与$P_{\theta_1}$

证明思路：
- 对于每个给定的检验水平，都存在一个具有**特定形式**的检验函数；
- 由上述检验水平和**特定形式**确定的检验函数，其是MPT；
- 如果一个检验函数是上述检验水平下的MPT，则其一定在「几乎处处」的意义下具有**特定形式**。

 这个特定形式就是：
 $\phi(x) = 1, p(x;\theta_1) > k * p(x; \theta_0)$
 $\phi(x) = r, p(x;\theta_1) = k * p(x; \theta_0)$
 $\phi(x) = 0, p(x;\theta_1) < k * p(x; \theta_0)$
 
`e.g. 依赖充分统计量的三个MPT检验函数`

####  MPT的一个性质
如果$\phi(x)$是水平为$\alpha$的最优势检验函数，则$E_{\theta_1}\phi(X) \geqslant \alpha$. 且，当$\alpha \in (0,1)$时，除了$p(x; \theta_1) = p(x; \theta_0) a.e. [\mu]$外，必有$E_{\theta_1}\phi(X) > \alpha$.

这个结论很显然呀~就是说，在「备择假设为真」时，拒绝原假设的的概率，肯定要大于原假设为真的情况下的拒绝概率。


> **过渡：**   从「不能更简单」到「简单」

一般来说，对于复合假设的检验问题，MPT的$\phi(x)$依赖备择假设中的$\theta$值，此时，UMPT不一定存在。（恩，就是，凭啥有个东西对于所有变量都是最优的呢~？（眨下眼：）

那么，什么情况下存在，什么情况下不存在呢？接下来，引入了**单调似然比&单参数指数型分布族**后，我们可以讨论下以下几种情况(1&2是单边假设检验问题，3-5为双边假设检验问题)：

- no.1 $H_{0}: \theta \leqslant \theta_0 \leftrightarrow H_{1}: \theta >\theta_0$
- no.2 $H_{0}: \theta \geqslant \theta_0 \leftrightarrow H_{1}: \theta <\theta_0$
- no.3 $H_{0}: \theta = \theta_0 \leftrightarrow H_{1}: \theta \neq \theta_0$
-  no.4 $H_{0}: \theta_{1} \leqslant \theta \leqslant \theta_{2} \leftrightarrow H_{1}: \theta <\theta_1 or  \theta > \theta_{2}$
-  no.5 $H_{0}: \theta  \leqslant \theta_{1}  or  \theta \geqslant \theta_{2} \leftrightarrow H_{1}: \theta_1 < \theta < \theta_{2}$

####单调性的力量——单调似然比-统计量-势函数
如果概率密度族$\{p(x;\theta): \theta \in \Theta \subseteq R\}$关于$T(x)$具有非降的MLR，若$\psi(t)$是t的一个非降函数，则$E_{\theta}\psi (T(X))$是$\theta$的一个非降函数

> 接下来的定理要证明的其实**很直观**——在概率密度族关于$T(x)$具有非降MLR时，如果考虑单边假设检验问题no.1，不应该在$T(x)$比较大的时候拒绝原假设嘛？

####单边假设检验问题的UMPT

单参数概率密度族$\{p(x;\theta): \theta \in \Theta \subseteq R\}$关于实值统计量$T(x)$具有非降MLR，则关于单边假设检验问题no.1 $H_{0}: \theta \leqslant \theta_0 \leftrightarrow H_{1}: \theta >\theta_0$：
1. 存在水平为$\alpha$的UMPT的检验函数
 $\phi(x) = 1, T(x) > c$
 $\phi(x) = r, T(x) = c$
 $\phi(x) = 0, T(x) < c$
其中常数r与c由$E_{\theta_{0}}\phi(T(x)) = \alpha$确定
2. 这个检验的势函数非降且在集合$\{\theta: 0< g(\theta) <1\}$上严格增加
3. 在一切使得$E_{\theta_{0}}\phi(X) = \alpha$的检验函数中，由1确定的检验函数$\phi(T(x))$使得对任意的$\theta < \theta_{0}$，$E_{\theta}\phi(X)$都达到最小。

> 用人话说复述以上三点：

`第一点「真的存在UMPT呢，我就是，我长这样」`
`第二点「长这样的我，随着参数的变大，我会越来越严厉的，一不开心呢就把原假设拒绝了哦」`
`我最喜欢这些定理的第三点，很傲娇哦「没错，在单调性的帮助下，落在原假设的参数们，如果你们是真的，我犯错的可能性最小哦！所向披靡！」`


有没有觉得很熟悉，在简单假设vs简单假设时，MPT长这样哦！在我们引入MLR后，就可以同统计量来代替单调似然比了，也更方便操作，更能借鉴统计量中蕴含的智慧：）

 $\phi(x) = 1, p(x;\theta_1) > k * p(x; \theta_0)$
 $\phi(x) = r, p(x;\theta_1) = k * p(x; \theta_0)$
 $\phi(x) = 0, p(x;\theta_1) < k * p(x; \theta_0)$

> 过渡 ：终于从单边假设到了双边假设了

双边假设检验问题no.5 $H_{0}: \theta  \leqslant \theta_{1}  or  \theta \geqslant \theta_{2} \leftrightarrow H_{1}: \theta_1 < \theta < \theta_{2}$的UMPT是存在的，但是no.3&no.4都是不存在的。
一个一个来，先解决no.5的存在性问题吧：）

####N-P基本引理的推广（一）
 $k_1 ... k_m$且其非负
$\alpha_{1} ... \alpha_m$
$p_1 ... p_m$

设$\mu$是可测空间$X, B$上的测度，$p_{0}, p_{1}, ..., p_{m}$为该测度空间上$m+1$个实可测且$\mu$可积的函数. $\alpha_{1}, \alpha_{m}$为给定的m个实常数，如果存在检验函数$\phi(x)$满足以下两个条件：
1. 有m个非负常数$k_{1},\ldots,k_{m}$使得
$\phi(x)=1, p_{0}(x) > \sum_{i=1}^{m}k_{i}*p_{i}(x)$
$\phi(x)=0, p_{0}(x) < \sum_{i=1}^{m}k_{i}*p_{i}(x)$
2. $\int\phi(x)*p_{i}(x)d\mu(x) =\alpha_{i}$

则对任意满足下式的检验函数$\phi'(x)$, $\int\phi'(x)*p_{i}(x)d\mu(x) \leqslant\alpha_{i}, i=1,\ldots,m$
都有
$\int\phi(x)*p_{0}(x)d\mu(x) \geqslant\int\phi'(x)*p_{i}(x)d\mu(x)$


`闲聊两句`

N-P基本引理和N-P基本引理的推广，实际上主要的思想都一样「犯第一类错误的概率小于$\alpha$的情况下，存在最好的检验函数——犯第二类的错误最小，它有特定的形式，特定形式的参数是在下述条件时得出的——充分利用了我们对于第一类错误的『包容度』，即势函数等于给定的$\alpha$. 

引理的推广，可以看做，我们有不止一个原假设，对于每个原假设的参数$\theta_{i}$，我们有不同的第一类错误的包容度$\alpha_{i}$，然后我们希望检验函数犯第二类错误的概率最小，即当参数的真实值为$p_{0}$时，我们会雄赳赳气昂昂地拒绝原假设，其最优性就表现在$\int\phi(x)*p_{0}(x)d\mu(x) \geqslant\int\phi'(x)*p_{i}(x)d\mu(x)$」

真是喜欢这样的质朴纯粹的结论啊:

-  「最好的，就是长这样的，你只要解几个参数就可以啦」
- 「长这样的，就是最好的，与其它表现最好的，差异可忽略不计」

####单参数指数型分布族的双边假设检验问题（一）
设样本服从单参数指数族分布，其中$\theta$为实参数，$Q(\theta)$是严增函数，则关于双边假设检验问题no.5-  no.5 $H_{0}: \theta  \leqslant \theta_{1}  or  \theta \geqslant \theta_{2} \leftrightarrow H_{1}: \theta_1 < \theta < \theta_{2}$, 存在水平为$\alpha$的UMPT，其检验函数仅依赖于充分统计量$T(x)$，形如：
 $\phi(x) = 1, c_{1}< T(x) < c_{2}$
 $\phi(x) = r_i, T(x) = c_{i}, i=1, 2$
 $\phi(x) = 0, T(x) < c_{1} or T(x) > c_{2}$
其中常数$r_i$与$c_{i}$由$E_{\theta_{i}}\phi(T(x)) = \alpha$确定

`证明要点`
从N-P基本引理的推广（一）到单指数型分布族的双边假设检验问题的推论，结果的差异只在于用$T(x)$代替$p_{i}(x)$，这一步的转换与讨论需要借助单参数指数型分布族一个非常好的性质「指数型分布族的充分统计量还是单参数指数型分布族」，况且，我们还有$Q(x)$的单调性呢~


> 过渡
N-P基本引理的推广（一）帮助我们解决了no.5$H_{0}: \theta  \leqslant \theta_{1}  or  \theta \geqslant \theta_{2} \leftrightarrow H_{1}: \theta_1 < \theta < \theta_{2}$，为了解决双边假设检验no.3和no.4（备择假设区间不连续）

我们需要把N-P再推广一下，N-P基本引理的推广（二）与（一）的不同在于常数$k_1, \ldots,k_m$可以取为负数。同时，我们降低一下要求，从寻找「一致最优检验」降低到「一致最优无偏检验」


####单参数指数型分布族的双边假设检验问题（二）

- 待解决的问题1：

no.3 $H_{0}: \theta = \theta_0 \leftrightarrow H_{1}: \theta \neq \theta_0$

嗯~这里有个小定理：
设样本服从单参数指数族分布，其中$\theta$为实参数，$Q(\theta)$是严增函数。关于no.3的双边假设检验问题，存在水平为$\alpha$的UMPUT，其检验函数为：

 $\phi(x) = 1, T(x) < c_{1} or T(x) > c_{2}$
 $\phi(x) = r, T(x) = c_{i}, i=1, 2$
 $\phi(x) = 0, c_{1}< T(x) < c_{2}$

其中常数$r_i$与$c_{i}$由以下两个式子确定：

$E_{\theta_{0}}\phi(T(X)) = \alpha$
$E_{\theta_{0}}[T(X)\phi(T(X)) = \alpha*E_{\theta_{0}} T(X)$



- 待解决的问题2：

no.4 $H_{0}: \theta_{1} \leqslant \theta \leqslant \theta_{2} \leftrightarrow H_{1}: \theta <\theta_1 or  \theta > \theta_{2}$

嘿~这里还有个小定理：
设样本服从单参数指数族分布，其中$\theta$为实参数，$Q(\theta)$是严增函数。关于no.4的双边假设检验问题，存在水平为$\alpha$的UMPUT，其检验函数为：

 $\phi(x) = 1, T(x) < c_{1} or T(x) > c_{2}$
 $\phi(x) = r_i, T(x) = c_{i}, i=1, 2$
 $\phi(x) = 0, c_{1}< T(x) < c_{2}$
 
其中常数$r_i$与$c_{i}$由$E_{\theta_{i}}\phi(T(X)) = \alpha$确定



> 在周六的早晨，绕着西湖跑了久违的5km后，回到宿舍把继续写了写复习笔记，感觉很好呢～
> 但是，假设检验内容也太多了（委屈1秒钟）

> 以上 2016.06.04
<!-- markdown end -->
</div>
<div class="entry" id="main">
<!-- content -->
<h1 id="mathematicalstatisticalreviewnotes">Mathematical Statistical Review Notes</h1>

<p></p><center>目录</center><p></p>

<p><strong>Mathematical Statistical</strong></p>

<ul>
<li><p>假设检验</p>

<ul><li>从几个问题入手</li>
<li>假设检验问题的基本概念</li>
<li><p>漂亮的定理证明</p>

<ul><li>随机化检验的优良性「充分性原则」</li>
<li>Neyman-Pearson 基本引理</li>
<li>MPT的一个性质</li>
<li>单调性的力量——单调似然比-统计量-势函数</li>
<li>单边假设检验问题的UMPT</li>
<li>N-P基本引理的推广（一）</li>
<li>单参数指数型分布族的双边假设检验问题（一）</li>
<li>单参数指数型分布族的双边假设检验问题（二）</li></ul></li></ul></li>
</ul>

<p>Statistics很火没有错，但是Mathematical Statistical一直一来都不温不火，太优雅门槛高变现不容易。若心浮浮躁躁，想来也是学不下去的。</p>

<p>突然想到自己大三的时候，那时还住在本科院校一个四面环山的校区，突然想到一个事「我们单身的时候都会非常羡慕他人有陪伴，但是单身这种状态本身也是值得享受的呢，而且它持续的时间也不会很长，假设30岁结婚，最多也只有10年。」</p>

<p>比较幸运的是，我在自己单身的时候就明白了这一点，而且充分享受了一个人&amp;无牵绊&amp;宅宅的&amp;简单纯粹&amp;看似孤独实则轻松得想要偷笑的生活。</p>

<p>面对考试前的二十天，虽然不可免俗地要和身边的人共同「抱怨期末考」，但是，如同我对待「一个人的日子」那般，我也会好好享受这段「一支笔&amp;一张纸」就是全部生产力的日子。</p>

<p>那么以下就是我的复习笔记了，也想留下点什么纪念下：）</p>

<p>ps：以下内容并非原创哦！整理自三本参考书：
- <a href="https://book.douban.com/subject/4102672/">《高等数理统计学》</a>
- <a href="https://book.douban.com/subject/1832818/">《高等数理统计(第二版)》 </a>
- <a href="https://book.douban.com/subject/1522839/">《数理统计学简史》</a>
- <a href="https://book.douban.com/subject/24316364/">《统计学：从数据到结论》</a></p>

<p>关于这三本参考书，难度或者说抽象程度，由高到低。
- <a href="https://book.douban.com/subject/4102672/">《高等数理统计学》》</a>是陈希孺前辈的著作，定位是「基于测度论的数理统计学基础教科书，主体是几种基本统计推断形式：点估计、区间估计、假设检验的理论与方法。」这本书中习题以及提示占了50%的篇幅，的确，基础学科若不以做题加深功底，就如同「入宝山而空返」。
- <a href="https://book.douban.com/subject/1832818/">《高等数理统计(第二版)》 </a>是陈希孺的学生们基于教学工作写就的，理论讲解和习题举例结合得比较好，通俗地讲就是比较简单，但是这个简单是相对于《高等数理统计学》而言的哦！
- <a href="https://book.douban.com/subject/1522839/">《数理统计学简史》</a>也是陈希孺为大众写的一本书，侧重的是统计学的艺术性，其强调人的见解和灵感的部分，这四本书中，唯有这一本阅读人数&gt;100，评分高于9.0, 看来广大豆友们还是偏爱自己能看懂的书（眨眼&amp;不置可否）
- <a href="https://book.douban.com/subject/24316364/">《统计学：从数据到结论》</a>是吴喜之老先生的著作，比较难能可贵的一点是这本书兼顾统计见解&amp;实用性——书中附有R的代码。看上去非常舒服：）</p>

<p></p><center> <strong>那就开始吧</strong> </center><p></p>

<h2 id="1">1. 假设检验</h2>

<h3 id="11">1.1 从几个问题入手</h3>

<p>常用的U检验、t检验、F检验都有足够的直观性和可信感。再往深处想：</p>

<ul>
<li>一个好的检验究竟「好」在哪里？</li>
<li>对于给定的「好坏」标准，是否存在最优的检验方法？</li>
<li>如果有，如何找到？</li>
</ul>

<h3 id="12">1.2 假设检验问题的基本概念</h3>

<p>统计结构 $(X, B, P)$中：</p>

<ol>
<li><strong>假设</strong>：原假设为 $H_{0}$, 备择假设为$H_{1}$ ，都是 P 的非空子集，且不相交或者更广义地说，是可以用样本点——「我们的观测值」，来进行检验的「任何说法」。所以啊，样本点身兼两大重任——「参数估计」&amp;「假设检验」。</li>
<li><strong>检验法则</strong> $\leftrightarrow$ 拒绝域 $\rightarrow$ 统计量：检验法则将样本空间划分为互不相交的两个可测集 $X=W \oplus \overline W$ ，当样本点 $x \in W$  时就拒绝原假设 $H_0$ 。</li>
<li><strong>检验统计量</strong>：从另一个角度来看，确定拒绝域也就确定了检验法则，进一步，通常利用一个在$W$和 $\overline W$上表现得非常不一致的统计量来确定拒绝域。</li>
<li><p><strong>势函数</strong>：样本观察值X落在拒绝域W中的概率，即：</p>

<p>$g(\theta) = P_{\theta}(X \in W), \theta \in \Theta$ </p>

<p>其中:</p>

<p>第一类错误 $\alpha(\theta) = g(\theta), \theta \in \Theta_{0}$ </p>

<p>第二类错误 $\beta(\theta) = 1 - g(\theta), \theta \in \Theta_{1}$  </p>

<p>唉，忘了怎么写不属于的符号，就只能连式子都改一下了。所以，不同的检验法则会有不同的拒绝域，也就有不同的势函数，不同的犯第一类错误以及第二类错误的可能性</p></li>
<li><strong>检验的水平</strong>$\alpha$：犯第一类错误概率小于$\alpha$</li>
<li><p><strong>随机化检验</strong>：为了充分利用检验水平，引入随机化检验作为检验函数$\phi(x)$，此时势函数 $g(\theta) = P<em>{\theta}(X \in W) = E</em>{\theta}(\phi(x))$</p></li>
<li><p><strong>最优势检验（Most Powerful Test，MPT）</strong>：在大家犯第一类错误的概率都小于$\alpha$的基础上，犯第二类错误最小的检验函数$\phi(x)$即为最优势检验</p></li>
<li><p>从MPT到 <strong>Uniformly Most Powerful Test——UMPT</strong>，MPT是在简单原假设Vs简单备择假设的情况下得出的，但是面对复合假设时，如何定义最优？能否找到最优呢？这个问题一下子变得有些复杂。且看之~
<strong>定义UMPT</strong>
$\phi(x)$是水平为$\alpha$的检验，如果对于任意一个水平为$\alpha$的检验$\phi<em>{1}(x)$，都有$E</em>{\theta<em>1}[\phi(X)] &gt; E</em>{\theta<em>1}(\phi</em>{1}(X)),  \forall \theta<em>1 \in \Theta</em>1$，则$\phi(X)$就是水平为$\alpha$的UMPT.  (「一致性」表现在随着$ \theta<em>1 \in \Theta</em>1$不停地变换，「我」都是最好的哦！)
<strong>借由MPT得到UMPT</strong>
在一些特殊的情况下，可以通过MPT推导出UMPT。例如：当简单原假设对简单备择假设的检验问题的MPT不依赖于备择假设的具体数值，则可以适当扩大备择假设；当势函数是单调函数时，可以扩大<strong>原假设</strong>。BUT，但是在大部分情况下都无法将复杂假设还原到简单原假设，</p></li>
<li><strong>单调似然比</strong>，概率密度族${p(x; \theta): \theta \in \Theta}$关于统计量$T(X)$有单调似然比$\lambda(x) = \frac{p(x;\theta<em>2)}{p(x;\theta</em>1)}, \theta<em>{2} &gt; \theta</em>1$</li>
<li><strong>单参数指数族</strong>，$p(x;\theta) = c(\theta)<em>exp{Q(\theta)T(x)}</em>h(x)$，常见的有二项分布族、Poisson分布族、有1参数已知的正态分布族</li>
<li>从一致最优检验到<strong>一致最优势无偏检验 Uniformly Most Powerful Unbiased Test UMPUT</strong>，无偏检验满足：
$E<em>{\theta}[\phi(X)] \leqslant \alpha, \forall \theta \in \Theta</em>{0}$
$E<em>{\theta}[\phi(X)] \geqslant \alpha, \forall \theta \in \Theta</em>{1}$
一致最优说的就是:
$E<em>{\theta}[\phi(X)] \geqslant E</em>{\theta}[\phi'(X)] , \forall \theta \in \Theta<em>{1}$
12.从UMPUT到<strong>相似检验</strong>，在$\Theta</em>{0}$和$\Theta_{1}$的公共边界上势函数相等的检验函数是边界相似检验。构造边界相似检验比构造无偏检验更方便（前者束缚更小），如果$\phi(x)$是边界相似检验中的UMPT，则$\phi(x)$是水平为$\alpha$的UMPUT</li>
</ol>

<h3 id="13">1.3 漂亮的定理证明</h3>

<h4 id="">随机化检验的优良性「充分性原则」</h4>

<p>检验函数$\Leftrightarrow$势函数。对于任何一个检验函数，存在一个只依赖于$\theta$的充分统计量$T(x)$的另一个检验函数$\varphi(t) = E[\phi(X)| T=t]$，与之等价。
 <code>证明非常漂亮:</code> $E<em>{\theta}[\phi(T(X))] = E</em>{\theta}{E[\phi(X)| T]} = E_{\theta}[\varphi(T)]$</p>

<h4 id="neymanpearson">Neyman-Pearson 基本引理</h4>

<p>ok，首先考虑简单原假设对简单备择假设，简而言之就是参数$\theta$到底是$\theta<em>0$呢？还是$\theta</em>1$？</p>

<p>在这种最简单的情形下，N-P引理给出了非常漂亮的结果。</p>

<blockquote>
  <p>MPT一定存在，且可以具体地构造出MPT的检验函数。</p>
</blockquote>

<p>原假设$\theta = \theta<em>0$
备择假设$\theta = \theta</em>1$
分别对应两个不同的概率测度$P<em>{\theta</em>0}$与$P<em>{\theta</em>1}$</p>

<p>证明思路：
- 对于每个给定的检验水平，都存在一个具有<strong>特定形式</strong>的检验函数；
- 由上述检验水平和<strong>特定形式</strong>确定的检验函数，其是MPT；
- 如果一个检验函数是上述检验水平下的MPT，则其一定在「几乎处处」的意义下具有<strong>特定形式</strong>。</p>

<p>这个特定形式就是：
 $\phi(x) = 1, p(x;\theta<em>1) &gt; k * p(x; \theta</em>0)$
 $\phi(x) = r, p(x;\theta<em>1) = k * p(x; \theta</em>0)$
 $\phi(x) = 0, p(x;\theta<em>1) &lt; k * p(x; \theta</em>0)$</p>

<p><code>e.g. 依赖充分统计量的三个MPT检验函数</code></p>

<h4 id="mpt">MPT的一个性质</h4>

<p>如果$\phi(x)$是水平为$\alpha$的最优势检验函数，则$E<em>{\theta</em>1}\phi(X) \geqslant \alpha$. 且，当$\alpha \in (0,1)$时，除了$p(x; \theta<em>1) = p(x; \theta</em>0) a.e. [\mu]$外，必有$E<em>{\theta</em>1}\phi(X) &gt; \alpha$.</p>

<p>这个结论很显然呀~就是说，在「备择假设为真」时，拒绝原假设的的概率，肯定要大于原假设为真的情况下的拒绝概率。</p>

<blockquote>
  <p><strong>过渡：</strong>   从「不能更简单」到「简单」</p>
</blockquote>

<p>一般来说，对于复合假设的检验问题，MPT的$\phi(x)$依赖备择假设中的$\theta$值，此时，UMPT不一定存在。（恩，就是，凭啥有个东西对于所有变量都是最优的呢~？（眨下眼：）</p>

<p>那么，什么情况下存在，什么情况下不存在呢？接下来，引入了<strong>单调似然比&amp;单参数指数型分布族</strong>后，我们可以讨论下以下几种情况(1&amp;2是单边假设检验问题，3-5为双边假设检验问题)：</p>

<ul>
<li>no.1 $H<em>{0}: \theta \leqslant \theta</em>0 \leftrightarrow H<em>{1}: \theta &gt;\theta</em>0$</li>
<li>no.2 $H<em>{0}: \theta \geqslant \theta</em>0 \leftrightarrow H<em>{1}: \theta &lt;\theta</em>0$</li>
<li>no.3 $H<em>{0}: \theta = \theta</em>0 \leftrightarrow H<em>{1}: \theta \neq \theta</em>0$</li>
<li>no.4 $H<em>{0}: \theta</em>{1} \leqslant \theta \leqslant \theta<em>{2} \leftrightarrow H</em>{1}: \theta &lt;\theta<em>1 or  \theta &gt; \theta</em>{2}$</li>
<li>no.5 $H<em>{0}: \theta  \leqslant \theta</em>{1}  or  \theta \geqslant \theta<em>{2} \leftrightarrow H</em>{1}: \theta<em>1 &lt; \theta &lt; \theta</em>{2}$</li>
</ul>

<h4 id="">单调性的力量——单调似然比-统计量-势函数</h4>

<p>如果概率密度族${p(x;\theta): \theta \in \Theta \subseteq R}$关于$T(x)$具有非降的MLR，若$\psi(t)$是t的一个非降函数，则$E_{\theta}\psi (T(X))$是$\theta$的一个非降函数</p>

<blockquote>
  <p>接下来的定理要证明的其实<strong>很直观</strong>——在概率密度族关于$T(x)$具有非降MLR时，如果考虑单边假设检验问题no.1，不应该在$T(x)$比较大的时候拒绝原假设嘛？</p>
</blockquote>

<h4 id="umpt">单边假设检验问题的UMPT</h4>

<p>单参数概率密度族${p(x;\theta): \theta \in \Theta \subseteq R}$关于实值统计量$T(x)$具有非降MLR，则关于单边假设检验问题no.1 $H<em>{0}: \theta \leqslant \theta</em>0 \leftrightarrow H<em>{1}: \theta &gt;\theta</em>0$：
1. 存在水平为$\alpha$的UMPT的检验函数
 $\phi(x) = 1, T(x) &gt; c$
 $\phi(x) = r, T(x) = c$
 $\phi(x) = 0, T(x) &lt; c$
其中常数r与c由$E<em>{\theta</em>{0}}\phi(T(x)) = \alpha$确定
2. 这个检验的势函数非降且在集合${\theta: 0&lt; g(\theta) &lt;1}$上严格增加
3. 在一切使得$E<em>{\theta</em>{0}}\phi(X) = \alpha$的检验函数中，由1确定的检验函数$\phi(T(x))$使得对任意的$\theta &lt; \theta<em>{0}$，$E</em>{\theta}\phi(X)$都达到最小。</p>

<blockquote>
  <p>用人话说复述以上三点：</p>
</blockquote>

<p><code>第一点「真的存在UMPT呢，我就是，我长这样」</code>
<code>第二点「长这样的我，随着参数的变大，我会越来越严厉的，一不开心呢就把原假设拒绝了哦」</code>
<code>我最喜欢这些定理的第三点，很傲娇哦「没错，在单调性的帮助下，落在原假设的参数们，如果你们是真的，我犯错的可能性最小哦！所向披靡！」</code></p>

<p>有没有觉得很熟悉，在简单假设vs简单假设时，MPT长这样哦！在我们引入MLR后，就可以同统计量来代替单调似然比了，也更方便操作，更能借鉴统计量中蕴含的智慧：）</p>

<p>$\phi(x) = 1, p(x;\theta<em>1) &gt; k * p(x; \theta</em>0)$
 $\phi(x) = r, p(x;\theta<em>1) = k * p(x; \theta</em>0)$
 $\phi(x) = 0, p(x;\theta<em>1) &lt; k * p(x; \theta</em>0)$</p>

<blockquote>
  <p>过渡 ：终于从单边假设到了双边假设了</p>
</blockquote>

<p>双边假设检验问题no.5 $H<em>{0}: \theta  \leqslant \theta</em>{1}  or  \theta \geqslant \theta<em>{2} \leftrightarrow H</em>{1}: \theta<em>1 &lt; \theta &lt; \theta</em>{2}$的UMPT是存在的，但是no.3&amp;no.4都是不存在的。
一个一个来，先解决no.5的存在性问题吧：）</p>

<h4 id="np">N-P基本引理的推广（一）</h4>

<p>$k<em>1 ... k</em>m$且其非负
$\alpha<em>{1} ... \alpha</em>m$
$p<em>1 ... p</em>m$</p>

<p>设$\mu$是可测空间$X, B$上的测度，$p<em>{0}, p</em>{1}, ..., p<em>{m}$为该测度空间上$m+1$个实可测且$\mu$可积的函数. $\alpha</em>{1}, \alpha<em>{m}$为给定的m个实常数，如果存在检验函数$\phi(x)$满足以下两个条件：
1. 有m个非负常数$k</em>{1},\ldots,k<em>{m}$使得
$\phi(x)=1, p</em>{0}(x) &gt; \sum<em>{i=1}^{m}k</em>{i}<em>p_{i}(x)$
$\phi(x)=0, p_{0}(x) &lt; \sum_{i=1}^{m}k_{i}</em>p<em>{i}(x)$
2. $\int\phi(x)*p</em>{i}(x)d\mu(x) =\alpha_{i}$</p>

<p>则对任意满足下式的检验函数$\phi'(x)$, $\int\phi'(x)<em>p_{i}(x)d\mu(x) \leqslant\alpha_{i}, i=1,\ldots,m$
都有
$\int\phi(x)</em>p<em>{0}(x)d\mu(x) \geqslant\int\phi'(x)*p</em>{i}(x)d\mu(x)$</p>

<p><code>闲聊两句</code></p>

<p>N-P基本引理和N-P基本引理的推广，实际上主要的思想都一样「犯第一类错误的概率小于$\alpha$的情况下，存在最好的检验函数——犯第二类的错误最小，它有特定的形式，特定形式的参数是在下述条件时得出的——充分利用了我们对于第一类错误的『包容度』，即势函数等于给定的$\alpha$. </p>

<p>引理的推广，可以看做，我们有不止一个原假设，对于每个原假设的参数$\theta<em>{i}$，我们有不同的第一类错误的包容度$\alpha</em>{i}$，然后我们希望检验函数犯第二类错误的概率最小，即当参数的真实值为$p<em>{0}$时，我们会雄赳赳气昂昂地拒绝原假设，其最优性就表现在$\int\phi(x)*p</em>{0}(x)d\mu(x) \geqslant\int\phi'(x)*p_{i}(x)d\mu(x)$」</p>

<p>真是喜欢这样的质朴纯粹的结论啊:</p>

<ul>
<li>「最好的，就是长这样的，你只要解几个参数就可以啦」</li>
<li>「长这样的，就是最好的，与其它表现最好的，差异可忽略不计」</li>
</ul>

<h4 id="">单参数指数型分布族的双边假设检验问题（一）</h4>

<p>设样本服从单参数指数族分布，其中$\theta$为实参数，$Q(\theta)$是严增函数，则关于双边假设检验问题no.5-  no.5 $H<em>{0}: \theta  \leqslant \theta</em>{1}  or  \theta \geqslant \theta<em>{2} \leftrightarrow H</em>{1}: \theta<em>1 &lt; \theta &lt; \theta</em>{2}$, 存在水平为$\alpha$的UMPT，其检验函数仅依赖于充分统计量$T(x)$，形如：
 $\phi(x) = 1, c<em>{1}&lt; T(x) &lt; c</em>{2}$
 $\phi(x) = r<em>i, T(x) = c</em>{i}, i=1, 2$
 $\phi(x) = 0, T(x) &lt; c<em>{1} or T(x) &gt; c</em>{2}$
其中常数$r<em>i$与$c</em>{i}$由$E<em>{\theta</em>{i}}\phi(T(x)) = \alpha$确定</p>

<p><code>证明要点</code>
从N-P基本引理的推广（一）到单指数型分布族的双边假设检验问题的推论，结果的差异只在于用$T(x)$代替$p_{i}(x)$，这一步的转换与讨论需要借助单参数指数型分布族一个非常好的性质「指数型分布族的充分统计量还是单参数指数型分布族」，况且，我们还有$Q(x)$的单调性呢~</p>

<blockquote>
  <p>过渡
  N-P基本引理的推广（一）帮助我们解决了no.5$H<em>{0}: \theta  \leqslant \theta</em>{1}  or  \theta \geqslant \theta<em>{2} \leftrightarrow H</em>{1}: \theta<em>1 &lt; \theta &lt; \theta</em>{2}$，为了解决双边假设检验no.3和no.4（备择假设区间不连续）</p>
</blockquote>

<p>我们需要把N-P再推广一下，N-P基本引理的推广（二）与（一）的不同在于常数$k<em>1, \ldots,k</em>m$可以取为负数。同时，我们降低一下要求，从寻找「一致最优检验」降低到「一致最优无偏检验」</p>

<h4 id="">单参数指数型分布族的双边假设检验问题（二）</h4>

<ul>
<li>待解决的问题1：</li>
</ul>

<p>no.3 $H<em>{0}: \theta = \theta</em>0 \leftrightarrow H<em>{1}: \theta \neq \theta</em>0$</p>

<p>嗯~这里有个小定理：
设样本服从单参数指数族分布，其中$\theta$为实参数，$Q(\theta)$是严增函数。关于no.3的双边假设检验问题，存在水平为$\alpha$的UMPUT，其检验函数为：</p>

<p>$\phi(x) = 1, T(x) &lt; c<em>{1} or T(x) &gt; c</em>{2}$
 $\phi(x) = r, T(x) = c<em>{i}, i=1, 2$
 $\phi(x) = 0, c</em>{1}&lt; T(x) &lt; c_{2}$</p>

<p>其中常数$r<em>i$与$c</em>{i}$由以下两个式子确定：</p>

<p>$E<em>{\theta</em>{0}}\phi(T(X)) = \alpha$
$E<em>{\theta</em>{0}}[T(X)\phi(T(X)) = \alpha*E<em>{\theta</em>{0}} T(X)$</p>

<ul>
<li>待解决的问题2：</li>
</ul>

<p>no.4 $H<em>{0}: \theta</em>{1} \leqslant \theta \leqslant \theta<em>{2} \leftrightarrow H</em>{1}: \theta &lt;\theta<em>1 or  \theta &gt; \theta</em>{2}$</p>

<p>嘿~这里还有个小定理：
设样本服从单参数指数族分布，其中$\theta$为实参数，$Q(\theta)$是严增函数。关于no.4的双边假设检验问题，存在水平为$\alpha$的UMPUT，其检验函数为：</p>

<p>$\phi(x) = 1, T(x) &lt; c<em>{1} or T(x) &gt; c</em>{2}$
 $\phi(x) = r<em>i, T(x) = c</em>{i}, i=1, 2$
 $\phi(x) = 0, c<em>{1}&lt; T(x) &lt; c</em>{2}$</p>

<p>其中常数$r<em>i$与$c</em>{i}$由$E<em>{\theta</em>{i}}\phi(T(X)) = \alpha$确定</p>

<blockquote>
  <p>在周六的早晨，绕着西湖跑了久违的5km后，回到宿舍把继续写了写复习笔记，感觉很好呢～
  但是，假设检验内容也太多了（委屈1秒钟）</p>
  
  <p>以上 2016.06.04</p>
</blockquote>
<!-- content end -->
</div>
<br>
<br>
    <div id="disqus_thread"></div>
	<div class="footer">
		<p>© Copyright 2014 by isnowfy, Designed by isnowfy</p>
	</div>
</div>
<script src="main.js"></script>
<script id="content" type="text/mustache">
    <h1>{{title}}</h1>
    <div class="tag">
    {{date}}
    {{#tags}}
    <a href="/#/tag/{{name}}">#{{name}}</a>
    {{/tags}}
    </div>
</script>
<script id="pagesTemplate" type="text/mustache">
    {{#pages}}
    <li>
        <a href="{{path}}">{{title}}</a>
    </li>
    {{/pages}}
</script>
<script>
$(document).ready(function() {
    $.ajax({
        url: "main.json",
        type: "GET",
        dataType: "json",
        success: function(data) {
            $("#title").html(data.name);
            var pagesTemplate = Hogan.compile($("#pagesTemplate").html());
            var pagesHtml = pagesTemplate.render({"pages": data.pages});
            $("#pages").append(pagesHtml);
            //path
            var path = "stat.hypotest.html";
            //path end
            var now = 0;
            for (var i = 0; i < data.posts.length; ++i)
                if (path == data.posts[i].path)
                    now = i;
            var post = data.posts[now];
            var tmp = post.tags.split(" ");
            var tags = [];
            for (var i = 0; i < tmp.length; ++i)
                if (tmp[i].length > 0)
                    tags.push({"name": tmp[i]});
            var contentTemplate = Hogan.compile($("#content").html());
            var contentHtml = contentTemplate.render({"title": post.title, "tags": tags, "date": post.date});
            $("#main").prepend(contentHtml);
            if (data.disqus_shortname.length > 0) {
                var disqus_shortname = data.disqus_shortname;
                (function() {
                    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                })();
            }
        }
    });
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ["\\(", "\\)"]], processEscapes: true}});
</script>
</body>
</html>
